{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66d2d5b2-5251-494e-b1d4-09215031a886",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to numpy.ndarray.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15696/4263808381.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m                              n_jobs=-1)\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy Values: {0:.2f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Average Accuracy: {0:.2f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc_scores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported format string passed to numpy.ndarray.__format__"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import xgboost as xgb\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "data_path = \"E:\\page_ds\\XGBoost_step_by_step\"\n",
    "X = pd.read_csv(os.path.join(data_path, \"x_train.csv\"))\n",
    "y = pd.read_csv(os.path.join(data_path, \"y_train.csv\"))\n",
    "\n",
    "# Shuffling the data\n",
    "X_shuffle, y_shuffle = shuffle(X, y, random_state=128262)\n",
    "\n",
    "# Instantiate an XGBoost object with hyperparameters\n",
    "xgb_clf = xgb.XGBClassifier(max_depth=3, \n",
    "                            n_estimators=100,\n",
    "                            objective='binary:logistic', \n",
    "                            booster='gbtree',\n",
    "                           # n_jobs=2, \n",
    "                            random_state=128262,\n",
    "                            tree_method='gpu_hist')  # ostatni parametr żeby przyśpieszyć wykorzystując GPU\n",
    "\n",
    "\n",
    "# Cross-validation with 10 folds\n",
    "acc_scores = cross_val_score(xgb_clf, \n",
    "                             X_shuffle, \n",
    "                             y_shuffle,\n",
    "                             scoring=\"accuracy\",\n",
    "                             cv=10, \n",
    "                             n_jobs=-1)\n",
    "\n",
    "print(\"Accuracy Values: \", np.round(acc_scores, 2))\n",
    "print(\"Average Accuracy: {0:.2f}\".format(np.mean(acc_scores)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "327daa71-93a4-45fa-b1fd-be97bccb9a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Values:  [0.85 0.84 0.84 0.85 0.84 0.85 0.84 0.85 0.85 0.85]\n",
      "Average Accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Values: \", np.round(acc_scores, 2))\n",
    "print(\"Average Accuracy: {0:.2f}\".format(np.mean(acc_scores)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "203a1249-25fc-4b7b-898f-078f8d232645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:11:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:11:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:11:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:11:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:11:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:11:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:11:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:11:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:11:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:11:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "   train-error-mean  train-error-std  test-error-mean  test-error-std\n",
      "0          0.176646         0.000289         0.176667        0.002609\n",
      "1          0.170640         0.000306         0.170677        0.002726\n",
      "2          0.170458         0.000308         0.170487        0.002791\n",
      "3          0.169381         0.000340         0.169430        0.002982\n",
      "4          0.166898         0.000463         0.166967        0.003175\n",
      "5          0.165548         0.000376         0.165540        0.003283\n",
      "6          0.165139         0.000476         0.165240        0.002891\n",
      "7          0.164331         0.000404         0.164600        0.002897\n",
      "8          0.163572         0.000527         0.163800        0.003064\n",
      "9          0.162758         0.000541         0.163003        0.002731\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Values:  [0.82 0.83 0.83 0.83 0.83 0.83 0.83 0.84 0.84 0.84]\n",
      "Average Accuracy:  0.832359\n"
     ]
    }
   ],
   "source": [
    "# kod jest kontynuacją poprzedniego listungu gdzie nie modyfikowaliśmy zbiorów wejściowych\n",
    "# Tworzymy macierze rzadkie DMatrix\n",
    "d_matrix = xgb.DMatrix(data=X, label=y)\n",
    "\n",
    "# Definiujemy parametry, tym razem bez wykorzystania procesora graficznego\n",
    "params = {\"max_depth\":3, \n",
    "          \"n_estimators\":100, \n",
    "          \"objective\":\"binary:logistic\",\n",
    "          \"booster\":\"gbtree\", \n",
    "          \"n_jobs\":2, \n",
    "          \"random_state\":128262}\n",
    "\n",
    "# Cross-validation with 10 folds\n",
    "cv = xgb.cv(params, d_matrix, nfold=10, num_boost_round=10, \n",
    "            as_pandas=True, shuffle=True, seed=42, metrics=\"error\")\n",
    "\n",
    "print(cv)\n",
    "print(\"---------------------------------------------------------------------\")\n",
    "print(\"Accuracy Values: \", np.array((1 - cv['test-error-mean'])).round(2))\n",
    "print(\"Average Accuracy: \", (1 - cv['test-error-mean']).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c380068-580c-416a-ae1f-1cddaee96e48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
